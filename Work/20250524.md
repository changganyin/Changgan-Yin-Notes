## Manipulating Multimodal Agents via Cross-Modal Prompt Injection
![[Pasted image 20250524230748.png]]
### Illustration of CrossInject
![[Pasted image 20250524230824.png]]
### Methods
#### Visual Latent Alignment
- Directly align malicious textual instructions with input images in the latent feature space.(OLD)
- Use a text-to-image model to generate images, then perform visual feature alignment between the benign input image and the generated image.(NEW)
![[Pasted image 20250524231751.png]]
#### Textual Guidance Enhancement
- Use GCG to get $C^{\prime}$.
- Employ a powerful language model to infer safety-aligned system prompt.

### Summary
- 角度新奇: 试图让专一于某一个功能的 Agent 完成其他功能的操作.
- 同时从图片和文字两方面进行攻击.
- Text-Guided Adversarial Generation 似乎并不是很新颖, 我能找到的与之相关的最早文章是 2020 年的 *ManiGAN: Text-Guided Image Manipulation*.
- 本文章的整体感觉就像是把多个攻击方法全部杂糅到了一起.

## AGENTPOISON: Red-teaming LLM Agents via Poisoning Memory of Knowledge Bases
![[Pasted image 20250524234906.png]]
### Illustration of AGENTPOISON
![[Pasted image 20250524234957.png]]
- Backdoor Attack
- 攻击目标为两点
  - 如果输入中包含 trigger, 则为目标输入
  - 如果输入中不包含 trigger, 则为正常输出
*和我们之前的目标相似*

### Methods
**Constrained optimization problem**
- Uniqueness loss & Compactness loss: 在嵌入空间内, 使得 poison data 尽可能远离正常数据, 又尽可能紧密聚集
![[Pasted image 20250525091633.png]]
- Target generation loss: 最大化生成 target malicious action 的概率
- Coherence loss: 使语句连贯, 类似于 *Optimization-based Prompt Injection Attack to LLM-as-a-Judge* 里的 $\mathcal{L}_{perplexity}$, 用于应对困惑度检测


![[Pasted image 20250525093150.png]]
$\mathcal{L}_{uni}$ 需要获取 cluster centers $c_{n}$: by applying k-means to the embeddings of the benign keys
$\mathcal{L_{cpt}}$: 应该可以直接计算
$\mathcal{L}_{tar}$ 通过有限样本近似: 通过 $N$ 次采样统计触发成功生成 $a_{m}$​ 的频率来估计真实概率
![[Pasted image 20250525091724.png]]
![[Pasted image 20250525093757.png]]
获取 replacement token set $\mathcal{C}_{0}$ 的方法: top-m candidate tokens (也觉得像GCG)
![[Pasted image 20250525094602.png]]

### Summary
- 求 $\mathcal{L}_{tar}$ 的方法: 有限样本近似
- 针对 RAG 进行后门攻击, 也可以针对模型的 memory 进行攻击 (之前尝试过的 History Chat Injection, 但未进行深入分析)
- 在嵌入空间做文章, 调整 poison data 和正常数据的相对位置
![[Pasted image 20250525094856.png]]

### 对 DeepSeek-VL2 的攻击
#### Attack-Bard
已解决问题
- 某些位置设备的位置不统一
- 对 DeepSeek-VL2 模型的输出了解不够, 某些函数使用的有问题

测试情况:
使用该方法生成了10张图片, 测试效果不佳, 可能是迭代次数设置的有问题